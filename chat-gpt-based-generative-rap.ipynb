{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a246533a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:24.137209Z",
     "iopub.status.busy": "2023-06-13T07:43:24.136325Z",
     "iopub.status.idle": "2023-06-13T07:43:40.872773Z",
     "shell.execute_reply": "2023-06-13T07:43:40.871144Z"
    },
    "papermill": {
     "duration": 16.745817,
     "end_time": "2023-06-13T07:43:40.875278",
     "exception": false,
     "start_time": "2023-06-13T07:43:24.129461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chat-gpt-rap-ai/Chat GPT Rap Data.txt\n",
      "/kaggle/input/data-1/Chat GPT Rap Data.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d76545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:40.887672Z",
     "iopub.status.busy": "2023-06-13T07:43:40.886192Z",
     "iopub.status.idle": "2023-06-13T07:43:40.897615Z",
     "shell.execute_reply": "2023-06-13T07:43:40.896602Z"
    },
    "papermill": {
     "duration": 0.019772,
     "end_time": "2023-06-13T07:43:40.900184",
     "exception": false,
     "start_time": "2023-06-13T07:43:40.880412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/kaggle/input/data-1/Chat GPT Rap Data.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5b068d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:40.912883Z",
     "iopub.status.busy": "2023-06-13T07:43:40.911068Z",
     "iopub.status.idle": "2023-06-13T07:43:40.918953Z",
     "shell.execute_reply": "2023-06-13T07:43:40.917932Z"
    },
    "papermill": {
     "duration": 0.016104,
     "end_time": "2023-06-13T07:43:40.921211",
     "exception": false,
     "start_time": "2023-06-13T07:43:40.905107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b14cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:40.932601Z",
     "iopub.status.busy": "2023-06-13T07:43:40.931776Z",
     "iopub.status.idle": "2023-06-13T07:43:40.937950Z",
     "shell.execute_reply": "2023-06-13T07:43:40.936767Z"
    },
    "papermill": {
     "duration": 0.014815,
     "end_time": "2023-06-13T07:43:40.940810",
     "exception": false,
     "start_time": "2023-06-13T07:43:40.925995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", ',', '-', '.', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(list(char_to_int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3875f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:40.952030Z",
     "iopub.status.busy": "2023-06-13T07:43:40.951001Z",
     "iopub.status.idle": "2023-06-13T07:43:40.957829Z",
     "shell.execute_reply": "2023-06-13T07:43:40.956428Z"
    },
    "papermill": {
     "duration": 0.014617,
     "end_time": "2023-06-13T07:43:40.960120",
     "exception": false,
     "start_time": "2023-06-13T07:43:40.945503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  15036\n",
      "Total Vocab:  33\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb331a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:40.971036Z",
     "iopub.status.busy": "2023-06-13T07:43:40.970124Z",
     "iopub.status.idle": "2023-06-13T07:43:41.139143Z",
     "shell.execute_reply": "2023-06-13T07:43:41.137515Z"
    },
    "papermill": {
     "duration": 0.176977,
     "end_time": "2023-06-13T07:43:41.141656",
     "exception": false,
     "start_time": "2023-06-13T07:43:40.964679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  14936\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc300753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:41.151756Z",
     "iopub.status.busy": "2023-06-13T07:43:41.151374Z",
     "iopub.status.idle": "2023-06-13T07:43:41.354763Z",
     "shell.execute_reply": "2023-06-13T07:43:41.353794Z"
    },
    "papermill": {
     "duration": 0.2113,
     "end_time": "2023-06-13T07:43:41.357478",
     "exception": false,
     "start_time": "2023-06-13T07:43:41.146178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231118fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:41.369010Z",
     "iopub.status.busy": "2023-06-13T07:43:41.368662Z",
     "iopub.status.idle": "2023-06-13T07:43:48.468937Z",
     "shell.execute_reply": "2023-06-13T07:43:48.467966Z"
    },
    "papermill": {
     "duration": 7.108825,
     "end_time": "2023-06-13T07:43:48.471692",
     "exception": false,
     "start_time": "2023-06-13T07:43:41.362867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccf1c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:48.482229Z",
     "iopub.status.busy": "2023-06-13T07:43:48.481876Z",
     "iopub.status.idle": "2023-06-13T07:43:48.486672Z",
     "shell.execute_reply": "2023-06-13T07:43:48.485654Z"
    },
    "papermill": {
     "duration": 0.012528,
     "end_time": "2023-06-13T07:43:48.489051",
     "exception": false,
     "start_time": "2023-06-13T07:43:48.476523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8bce07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:43:48.498554Z",
     "iopub.status.busy": "2023-06-13T07:43:48.498248Z",
     "iopub.status.idle": "2023-06-13T07:46:20.469385Z",
     "shell.execute_reply": "2023-06-13T07:46:20.468397Z"
    },
    "papermill": {
     "duration": 151.97841,
     "end_time": "2023-06-13T07:46:20.471797",
     "exception": false,
     "start_time": "2023-06-13T07:43:48.493387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 3.0915\n",
      "Epoch 1: loss improved from inf to 3.09146, saving model to weights-improvement-01-3.0915.hdf5\n",
      "117/117 [==============================] - 15s 30ms/step - loss: 3.0915\n",
      "Epoch 2/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 3.0493\n",
      "Epoch 2: loss improved from 3.09146 to 3.04932, saving model to weights-improvement-02-3.0493.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 3.0493\n",
      "Epoch 3/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 3.0384\n",
      "Epoch 3: loss improved from 3.04932 to 3.03845, saving model to weights-improvement-03-3.0384.hdf5\n",
      "117/117 [==============================] - 3s 30ms/step - loss: 3.0384\n",
      "Epoch 4/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.9711\n",
      "Epoch 4: loss improved from 3.03845 to 2.97112, saving model to weights-improvement-04-2.9711.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.9711\n",
      "Epoch 5/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.8643\n",
      "Epoch 5: loss improved from 2.97112 to 2.86426, saving model to weights-improvement-05-2.8643.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.8643\n",
      "Epoch 6/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.7755\n",
      "Epoch 6: loss improved from 2.86426 to 2.77553, saving model to weights-improvement-06-2.7755.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.7755\n",
      "Epoch 7/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.6856\n",
      "Epoch 7: loss improved from 2.77553 to 2.68563, saving model to weights-improvement-07-2.6856.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.6856\n",
      "Epoch 8/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.5862\n",
      "Epoch 8: loss improved from 2.68563 to 2.58617, saving model to weights-improvement-08-2.5862.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.5862\n",
      "Epoch 9/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.4773\n",
      "Epoch 9: loss improved from 2.58617 to 2.47730, saving model to weights-improvement-09-2.4773.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.4773\n",
      "Epoch 10/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.3722\n",
      "Epoch 10: loss improved from 2.47730 to 2.37218, saving model to weights-improvement-10-2.3722.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.3722\n",
      "Epoch 11/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.2699\n",
      "Epoch 11: loss improved from 2.37218 to 2.26988, saving model to weights-improvement-11-2.2699.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.2699\n",
      "Epoch 12/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.1532\n",
      "Epoch 12: loss improved from 2.26988 to 2.15315, saving model to weights-improvement-12-2.1532.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 2.1532\n",
      "Epoch 13/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0431\n",
      "Epoch 13: loss improved from 2.15315 to 2.04305, saving model to weights-improvement-13-2.0431.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 2.0431\n",
      "Epoch 14/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9197\n",
      "Epoch 14: loss improved from 2.04305 to 1.91973, saving model to weights-improvement-14-1.9197.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 1.9197\n",
      "Epoch 15/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.8104\n",
      "Epoch 15: loss improved from 1.91973 to 1.81043, saving model to weights-improvement-15-1.8104.hdf5\n",
      "117/117 [==============================] - 3s 29ms/step - loss: 1.8104\n",
      "Epoch 16/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.6837\n",
      "Epoch 16: loss improved from 1.81043 to 1.68373, saving model to weights-improvement-16-1.6837.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 1.6837\n",
      "Epoch 17/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.5755\n",
      "Epoch 17: loss improved from 1.68373 to 1.57553, saving model to weights-improvement-17-1.5755.hdf5\n",
      "117/117 [==============================] - 3s 30ms/step - loss: 1.5755\n",
      "Epoch 18/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4729\n",
      "Epoch 18: loss improved from 1.57553 to 1.47294, saving model to weights-improvement-18-1.4729.hdf5\n",
      "117/117 [==============================] - 3s 30ms/step - loss: 1.4729\n",
      "Epoch 19/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.3576\n",
      "Epoch 19: loss improved from 1.47294 to 1.35765, saving model to weights-improvement-19-1.3576.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 1.3576\n",
      "Epoch 20/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2716\n",
      "Epoch 20: loss improved from 1.35765 to 1.27162, saving model to weights-improvement-20-1.2716.hdf5\n",
      "117/117 [==============================] - 3s 30ms/step - loss: 1.2716\n",
      "Epoch 21/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1785\n",
      "Epoch 21: loss improved from 1.27162 to 1.17848, saving model to weights-improvement-21-1.1785.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 1.1785\n",
      "Epoch 22/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0985\n",
      "Epoch 22: loss improved from 1.17848 to 1.09847, saving model to weights-improvement-22-1.0985.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 1.0985\n",
      "Epoch 23/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0213\n",
      "Epoch 23: loss improved from 1.09847 to 1.02128, saving model to weights-improvement-23-1.0213.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 1.0213\n",
      "Epoch 24/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9484\n",
      "Epoch 24: loss improved from 1.02128 to 0.94842, saving model to weights-improvement-24-0.9484.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.9484\n",
      "Epoch 25/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8866\n",
      "Epoch 25: loss improved from 0.94842 to 0.88661, saving model to weights-improvement-25-0.8866.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 0.8866\n",
      "Epoch 26/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8237\n",
      "Epoch 26: loss improved from 0.88661 to 0.82368, saving model to weights-improvement-26-0.8237.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.8237\n",
      "Epoch 27/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7573\n",
      "Epoch 27: loss improved from 0.82368 to 0.75726, saving model to weights-improvement-27-0.7573.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 0.7573\n",
      "Epoch 28/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.7212\n",
      "Epoch 28: loss improved from 0.75726 to 0.72116, saving model to weights-improvement-28-0.7212.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 0.7212\n",
      "Epoch 29/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6664\n",
      "Epoch 29: loss improved from 0.72116 to 0.66639, saving model to weights-improvement-29-0.6664.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.6664\n",
      "Epoch 30/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.6246\n",
      "Epoch 30: loss improved from 0.66639 to 0.62464, saving model to weights-improvement-30-0.6246.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 0.6246\n",
      "Epoch 31/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5868\n",
      "Epoch 31: loss improved from 0.62464 to 0.58678, saving model to weights-improvement-31-0.5868.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.5868\n",
      "Epoch 32/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5463\n",
      "Epoch 32: loss improved from 0.58678 to 0.54628, saving model to weights-improvement-32-0.5463.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.5463\n",
      "Epoch 33/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.5019\n",
      "Epoch 33: loss improved from 0.54628 to 0.50193, saving model to weights-improvement-33-0.5019.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.5019\n",
      "Epoch 34/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4719\n",
      "Epoch 34: loss improved from 0.50193 to 0.47195, saving model to weights-improvement-34-0.4719.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.4719\n",
      "Epoch 35/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4430\n",
      "Epoch 35: loss improved from 0.47195 to 0.44299, saving model to weights-improvement-35-0.4430.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.4430\n",
      "Epoch 36/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.4205\n",
      "Epoch 36: loss improved from 0.44299 to 0.42052, saving model to weights-improvement-36-0.4205.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.4205\n",
      "Epoch 37/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3871\n",
      "Epoch 37: loss improved from 0.42052 to 0.38712, saving model to weights-improvement-37-0.3871.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.3871\n",
      "Epoch 38/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3502\n",
      "Epoch 38: loss improved from 0.38712 to 0.35024, saving model to weights-improvement-38-0.3502.hdf5\n",
      "117/117 [==============================] - 4s 30ms/step - loss: 0.3502\n",
      "Epoch 39/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3433\n",
      "Epoch 39: loss improved from 0.35024 to 0.34326, saving model to weights-improvement-39-0.3433.hdf5\n",
      "117/117 [==============================] - 4s 31ms/step - loss: 0.3433\n",
      "Epoch 40/40\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.3323\n",
      "Epoch 40: loss improved from 0.34326 to 0.33235, saving model to weights-improvement-40-0.3323.hdf5\n",
      "117/117 [==============================] - 3s 30ms/step - loss: 0.3323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7871803b52d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=40, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25aa2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T07:46:20.900984Z",
     "iopub.status.busy": "2023-06-13T07:46:20.900638Z",
     "iopub.status.idle": "2023-06-13T07:47:25.886577Z",
     "shell.execute_reply": "2023-06-13T07:47:25.884635Z"
    },
    "papermill": {
     "duration": 65.200472,
     "end_time": "2023-06-13T07:47:25.888828",
     "exception": false,
     "start_time": "2023-06-13T07:46:20.688356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" killed navigator,\n",
      "my flow's so smooth, it's like a sweet sedator.\n",
      "i bring the fire, ignite the stage \"\n",
      " with my presence,\n",
      "when i'm on the mic, i leave an indelible essence.\n",
      "\n",
      "i'm the rap phenomenon, the wordsmith extraordinaire,\n",
      "i drop rhymes so sick, it's like a sonic warfare.\n",
      "from the east to the west, i'm known coast to coast,\n",
      "i'm the rap game's heavyweight, i boast and i toast.\n",
      "\n",
      "i'm the rap phenomenon, the wordsmith extraordinaire,\n",
      "i drop rhymes so sick, it's like a sonic warfare.\n",
      "from the east to the west, i'm known coast to coast,\n",
      "i'm the rap game's heavyweight, i boast and i toast.\n",
      "\n",
      "i'm the rap phenomenon, the wordsmith extraordinaire,\n",
      "i drop rhymes so sick, it's like a sonic warfare.\n",
      "from the east to the west, i'm known coast to coast,\n",
      "i'm the rap game's heavyweight, i boast and i toast.\n",
      "\n",
      "i'm the rap phenomenon, the wordsmith extraordinaire,\n",
      "i drop rhymes so sick, it's like a sonic warfare.\n",
      "from the east to the west, i'm known coast to coast,\n",
      "i'm the rap game's heavyweight, i boast and i toast.\n",
      "\n",
      "i'm the rap phenomenon, the wordsmith extraordinaire,\n",
      "i drop rhymes so sick, it's lik\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "# pattern = \"\"\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434969e",
   "metadata": {
    "papermill": {
     "duration": 0.23396,
     "end_time": "2023-06-13T07:47:26.390042",
     "exception": false,
     "start_time": "2023-06-13T07:47:26.156082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 260.97427,
   "end_time": "2023-06-13T07:47:30.101497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-13T07:43:09.127227",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
